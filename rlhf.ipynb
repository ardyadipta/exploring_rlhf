{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79c5855f-a6a9-4c48-bcf4-da7655d6e1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from torch.optim import Adam\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30ebe5f4-fc70-4df7-9891-3f9e5d2db4a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2502c48cc5fe402f93916fba216c6d71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d79a35c342e44318ae2d65694eb8087a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b827f2ef94e142fb8d5b876788dd02f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff738072859a4bbf8fb6dee217ec83ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ed997de2f77482685b79f8affb3d480",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a00aaebcf5c4f4b89b3eb5dcd5986e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2ae56cbecc5451aa144c5e26e7d6992",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"gpt2\"  # Replace with larger LLM for production use\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83ca9ea4-1876-4178-8415-f7565c1c5a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def human_feedback(response, expected_responses):\n",
    "    \"\"\"\n",
    "    Simulates human feedback by scoring responses. In practice, feedback\n",
    "    would come from real human ratings on response quality.\n",
    "    \"\"\"\n",
    "    return random.choice([1, 2, 3, 4, 5])  # Example rating (1 to 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2701b83d-1584-460b-b420-df32083863f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_reward(score):\n",
    "    \"\"\"Reward function based on human feedback score.\"\"\"\n",
    "    return score - 3  # Zero-centered (neutral response score at zero)\n",
    "\n",
    "def rl_training_loop(model, tokenizer, epochs=5, learning_rate=1e-5):\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "    model.train()\n",
    "\n",
    "    input_text = \"Why is the sky blue?\"  # Example input\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
    "        outputs = model.generate(input_ids, max_length=30)\n",
    "        response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        print(response)\n",
    "\n",
    "        # Get human feedback score\n",
    "        feedback_score = human_feedback(response, expected_responses=None)\n",
    "        reward = calculate_reward(feedback_score)\n",
    "\n",
    "        # Calculate RL loss (simplified here)\n",
    "        logits = model(input_ids).logits\n",
    "        loss = -reward * torch.sum(logits)  # Reward-weighted loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss.item()}, Feedback Score: {feedback_score}, Reward: {reward}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4636a19-6130-42e6-85b8-015cc4620de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why is the sky blue?\n",
      "\n",
      "The sky blue is a color that is used to represent the sky. It is a color that is used to\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 43681236.0, Feedback Score: 5, Reward: 2\n",
      "Why is the sky blue?\n",
      "\n",
      "The sky blue is a color that is used to indicate the color of the sky. The sky blue is a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: -24258132.0, Feedback Score: 2, Reward: -1\n",
      "Why is the sky blue?\n",
      "\n",
      "\n",
      "The sky blue is a colorless sky blue. It is a colorless sky blue.\n",
      "\n",
      "The\n",
      "Epoch 3/3, Loss: -0.0, Feedback Score: 3, Reward: 0\n"
     ]
    }
   ],
   "source": [
    "rl_training_loop(model, tokenizer, epochs=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33944cd-57b7-4c59-9033-03b8f72a4116",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
